<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="files/jemdoc.css" type="text/css" />
<style>
    .imgtable td {
        padding-top: 10px; /* 调整这个值以增加空间 */
    }
</style>
<title>Xiaodan Zhang-Home Page</title>
</head>
<body>

<div class="menu"> 
    <a href="#home"><b>Home</b></a>
    <a href="#publications"><b>Research</b></a>
    <a href="#awards"><b>Awards</b></a>
    <a href="#services"><b>Services</b></a>
    <a href="#laboratory"><b>Laboratory</b></a>
</div>

<a id="home" class="anchor"></a>
<div id="container"> 
<div class="container"> 
    
<div id="toptitle">
<h1>Xiaodan Zhang&nbsp;&nbsp;张晓丹</h1>
</div>

<table class="imgtable" width="100%">
    <tr>
        <td align="right">
            <p>
                Associate Professor, Master's Supervisor<br/>
                College of Computer Science, <a href="https://www.bjut.edu.cn/">Beijing University of Technology</a><br/>
                Email: <font face="courier new, monospace">zhangxiaodan@bjut.edu.cn</font><br/>
                <br/>
                <a href="https://scholar.google.com/citations?hl=zh-CN&user=iZDvOwIAAAAJ"><img src="./files/google_scholar.png" height="20px" style="margin-bottom:-3px">&nbsp;Google Scholar</a>&nbsp;
                <a href="https://github.com/zhangxiaodan-bjut"><img src="./files/github_s.jpg" height="20px" style="margin-bottom:-3px">&nbsp;Github</a>&nbsp;
                <!-- <a href="https://www.researchgate.net/profile/Yuting-He-17?ev=hdr_xprf"><img src="./files/rg.png" height="20px" style="margin-bottom:-3px">&nbsp;ResearchGate</a>&nbsp; -->
                <!-- <a href="https://drive.google.com/file/d/1fCahhpdNe__-Mo5VCY-cIpNDNle4jx0J/view?usp=share_link"><img src="./files/cv.png" height="20px" style="margin-bottom:-3px">&nbsp;Curriculum Vitae</a>&nbsp; -->
            </p>
        </td>
        <td align="left" width="250px">
            <!-- <img src="./files/yanzhaoshi.jpg" alt="" height="250px" /> -->
            <img src="./files/张晓丹-日常.jpg" alt="" height="250px" />
        </td>
    </tr>
</table>
    
<h2>Biography</h2>


I am an Associate Professor in the College of Computer Science and Beijing Institute of Artificial Intelligence, Beijing University of Technology. 
I obtained my Ph.D. degree from the University of Chinese Academy of Sciences in 2018 under the supervision of Prof. Jianbin Jiao and Prof. Qixiang Ye. 
I also obtained a joint Ph.D. degree from the City University of Hong Kong in 2018 under the supervision of Prof. Qingxiong Yang and Prof. Rynson W.H. Lau. 
My research focuses on critical theoretical and applied technologies in Artificial Intelligence, particularly Computer Vision and Natural Language Processing. 
I have published numerous papers in esteemed international journals and conferences, including IEEE TIP, Pattern Recognition, ACM MM, EMNLP, COLING, and IEEE ICME. 
I have also led and contributed to several National Natural Science Foundation projects and received funding for high-level overseas returnees from Beijing in 2022.
<br/>
<b>Research Interests:</b> Multimodal Large Language Models, Medical Image Processing, Computer Vision and Natural Language Processing


<h2>News</h2>
    <div style="overflow: auto;">
        <ul> 
            <li>[2024.09] One paper was accepted by EMNLP 2024 Findings.</li>
            <li>[2024.08] We proposed a LLM-based gaming AI (Llama_Dou) that achieves runner-up at the Chinese Collegiate Computer Gaming AI Contest.</li>
            <!-- <li>[2024.02] One paper was accepted by Multimedia Systems (JCR Q1).</li> -->
            <li>[2024.02] One paper was accepted by Multimedia Systems (JCR Q1).</li>
            <li>[2024.01] One paper was accepted by Multimedia Systems (JCR Q1).</li>
            <li>[2023.11] One paper was accepted by Computers in Biology and Medicine (JCR Q1).</li>
            <li>[2023.10] One paper was accepted to EMNLP 2023 (Oral Presentation) Paper.</li>
            <li>[2023.06] One paper was nominated as the best paper of ChinaMM 2023.</li>
            <li>[2023.05] Two papers were accepted to ChinaMM 2023 Paper.</li>
        </ul>
    </div>


<a id="publications" class="anchor"></a>
    
<h2>Publications [<a href="https://scholar.google.com/citations?hl=zh-CN&user=iZDvOwIAAAAJ" target="_blank">Google Scholar</a>]</h2>
    <h3>☆ Medical Report Generation</h3>
    <table class="imgtable" width="100%" bgcolor="#F0F0F0">
        <tr>
            <td>
                <p class="pub_title">See Detail Say Clear: Towards Brain CT Report Generation via Pathological Clue-driven Representation Learning.</p>
                <p class="pub_author">Chengxin Zheng, Junzhong Ji, Yanzhao Shi, <u><b>Xiaodan Zhang*</b></u>, Liangqiong Qu.<br/>
                <i>The 2024 Conference on Empirical Methods in Natural Language Processing</i> (<b>Findings</b>)</i><br/>
                <font color="#922B21"><b>&nbsp;EMNLP 2024 Findings&nbsp;</b></font>
                |<a href= "#">&nbsp;Paper&nbsp;</a>
                <!-- |<a href="https://github.com/ChenXiaoFei-CS/KoBo">&nbsp;Code&nbsp;</a> -->
                <!-- |<a href="./files/poster_KoBo.pdf">&nbsp;Poster&nbsp;</a> -->
                |<a href="#">&nbsp;Bibtex&nbsp;</a>
                </p>
            </td>
        </tr>
        <tr>
            <td>
                <p class="pub_title">Co-occurrence Relationship Driven Hierarchical Attention Network for Brain CT Report Generation.</p>
                <p class="pub_author"><u><b>Xiaodan Zhang</b></u>, Shixin Dou, Junzhong Ji, Ying Liu, Zheng Wang.<br/>
                <i>IEEE Transactions on Emerging Topics in Computational Intelligence</i><br/>
                <font color="#922B21"><b>&nbsp;TETCI 2024&nbsp;</b></font>
                |<a href= "https://api.semanticscholar.org/CorpusID:270605296">&nbsp;Paper&nbsp;</a>
                <!-- |<a href="https://github.com/ChenXiaoFei-CS/KoBo">&nbsp;Code&nbsp;</a> -->
                <!-- |<a href="./files/poster_KoBo.pdf">&nbsp;Poster&nbsp;</a> -->
                |<a href="./files/bib_CRDHAN.txt">&nbsp;Bibtex&nbsp;</a>
                </p>
            </td>
        </tr>
        <tr>
            <td>
                <p class="pub_title">Weakly Guided Attention Model with Hierarchical Interaction for Brain CT Report Generation.</p>
                <p class="pub_author"><u><b>Xiaodan Zhang</b></u>, Sisi Yang, Yanzhao Shi, Junzhong Ji*, Ying Liu, Zheng Wang and Huimin Xu.<br/>
                <i>Computers in Biology and Medicine</i><br/>
                <font color="#922B21"><b>&nbsp;Comput Biol Med 2023&nbsp;</b></font>
                |<a href= "https://doi.org/10.1016/j.compbiomed.2023.107650">&nbsp;Paper&nbsp;</a>
                <!-- |<a href="https://github.com/ChenXiaoFei-CS/KoBo">&nbsp;Code&nbsp;</a> -->
                <!-- |<a href="./files/poster_KoBo.pdf">&nbsp;Poster&nbsp;</a> -->
                |<a href="./files/bib_WGAM-HI.txt">&nbsp;Bibtex&nbsp;</a>
                </p>
            </td>
        </tr>
        <tr>
            <td>
                <p class="pub_title">Granularity Matters: Pathological Graph-driven Cross-modal Alignment for Brain CT Report Generation.</p>
                <p class="pub_author">Yanzhao Shi, Junzhong Ji, <u><b>Xiaodan Zhang*</b></u>, Liangqiong Qu* and Ying Liu.<br/>
                <i>The 2023 Conference on Empirical Methods in Natural Language Processing</i> (<b>Oral Long Paper</b>)<br/>
                <font color="#922B21"><b>&nbsp;EMNLP 2023&nbsp;</b></font>
                |<a href= "https://aclanthology.org/2023.emnlp-main.408/">&nbsp;Paper&nbsp;</a>
                <!-- |<a href="https://github.com/YutingHe-list/GVSL">&nbsp;Code&nbsp;</a> -->
                <!-- |<a href="./files/poster_GVSL.pdf">&nbsp;Poster&nbsp;</a> -->
                <!-- |<a href="./files/slide_GVSL.pdf">&nbsp;Slide&nbsp;</a> -->
                <!-- |<a href="https://x-ark.github.io/">&nbsp;Homepage&nbsp;</a> -->
                |<a href="./files/bib_PGCA.txt">&nbsp;Bibtex&nbsp;</a>
                <!-- |<a href="./files/paper_Chinese_GVSL.pdf">&nbsp;中译版&nbsp;</a> -->
                </p>
            </td>
        </tr>
        <tr>
            <td>
                <p class="pub_title">Prior Tissue Knowledge-Driven Contrastive Learning for Brain CT Report Generation.</p>
                <p class="pub_author">Yanzhao Shi, Junzhong Ji, <u><b>Xiaodan Zhang*</b></u>, Ying Liu, Zheng Wang and Huimin Xu.<br/>
                <i>Multimedia Systems</i><br>
                <font color="#922B21"><b>&nbsp;Multimedia Syst 2024&nbsp;</b></font>
                |<a href= "https://doi.org/10.1007/s00530-024-01289-w">&nbsp;Paper&nbsp;</a>
                |<a href="./files/bib_MRCL.txt">&nbsp;Bibtex&nbsp;</a>
                </p>
            </td>
        </tr>

        <tr>
            <td>
                <p class="pub_title">GHCL: Gaussian Heuristic Curriculum Learning for Brain CT Report Generation.</p>
                <p class="pub_author">Qingya Shen, Yanzhao Shi, <u><b>Xiaodan Zhang*</b></u>, Junzhong Ji, Ying Liu and Huimin Xu.<br/>
                <i>Multimedia Systems</i><br>
                <font color="#922B21"><b>&nbsp;Multimedia Syst 2024&nbsp;</b></font>
                |<a href= "https://doi.org/10.1007/s00530-024-01266-3">&nbsp;Paper&nbsp;</a>
                |<a href="./files/bib_GHCL.txt">&nbsp;Bibtex&nbsp;</a>
                </p>
            </td>
        </tr>

        <tr>
            <td>
                <p class="pub_title">Weakly Guided Hierarchical Encoder-Decoder Network for Brain CT Report Generation.</p>
                <p class="pub_author">Sisi Yang, Junzhong Ji, <u><b>Xiaodan Zhang*</b></u>, Ying Liu, and Zheng Wang.<br/>
                <i>IEEE International Conference on Bioinformatics and Biomedicine</i>(<b>Oral Long Paper</b>)<br>
                <font color="#922B21"><b>BIBM 2021</b></font>
                |<a href= "https://ieeexplore.ieee.org/abstract/document/9669626">&nbsp;Paper&nbsp;</a>
                |<a href="./files/bib_WGAM.txt">&nbsp;Bibtex&nbsp;</a>
                </p>
            </td>
        </tr>

        <tr>
            <td>
                <p class="pub_title">Cross-modal Contrastive Attention Model for Medical Report Generation.</p>
                <p class="pub_author">Xiao Song, <u><b>Xiaodan Zhang*</b></u>, Junzhong Ji, Ying Liu, Pengxu Wei.<br/>
                <i>In Proceedings of the 29th International Conference on Computational Linguistics</i>(<b>Oral Long Paper</b>)<br>
                <font color="#922B21"><b>COLING 2021</b></font>
                |<a href= "https://aclanthology.org/2022.coling-1.210">&nbsp;Paper&nbsp;</a>
                |<a href="./files/bib_CCAM.txt">&nbsp;Bibtex&nbsp;</a>
                </p>
            </td>
        </tr>

    </table>
    <h3>☆ Image Captioning</h3>
    <table class="imgtable" width="100%" bgcolor="#F0F0F0">
        <tr>
            <td>
                <p class="pub_title">Divergent-convergent Attention for Image Captioning.</p>
                <p class="pub_author">Junzhong Ji, Zhuoran Du, <u><b>Xiaodan Zhang*</b></u><br/>
                <i>Pattern Recognition</i><br/>
                <font color="#922B21"><b>PR 2021</b></font>
                |<a href= "https://doi.org/10.1016/j.patcog.2021.107928">&nbsp;Paper&nbsp;</a>
                |<a href="./files/bib_DCA.txt">&nbsp;Bibtex&nbsp;</a>
                <!-- |<a href="./files/paper_Chinese_GVSL.pdf">&nbsp;中译版&nbsp;</a> -->
                </p>
            </td>
        </tr>
        <tr>
            <td>
                <p class="pub_title">Spatio-temporal Memory Attention for Image Captioning.</p>
                <p class="pub_author">Junzhong Ji, Cheng Xu, <u><b>Xiaodan Zhang*</b></u>, Boyue Wang, Xinhang Song.<br/>
                <i>IEEE Transactions on Image Processing</i><br/>
                <font color="#922B21"><b>TIP 2020</b></font>
                |<a href= "https://ieeexplore.ieee.org/abstract/document/9130137/">&nbsp;Paper&nbsp;</a>
                |<a href="./files/bib_SMA.txt">&nbsp;Bibtex&nbsp;</a>
                <!-- |<a href="./files/paper_Chinese_GVSL.pdf">&nbsp;中译版&nbsp;</a> -->
                </p>
            </td>
        </tr>
        <tr>
            <td>
                <p class="pub_title">Image Captioning via Semantic Element Embedding.</p>
                <p class="pub_author"><u><b>Xiaodan Zhang</b></u>, Shengfeng He, Xinhang Song, Rynson W. H. Lau, Jianbin Jiao, Qixiang Ye.<br/>
                <i>Neurocomputing</i><br/>
                <font color="#922B21"><b>Neurocomput. 2020</b></font>
                |<a href= "https://doi.org/10.1016/j.neucom.2018.02.112">&nbsp;Paper&nbsp;</a>
                |<a href="./files/bib_SEE.txt">&nbsp;Bibtex&nbsp;</a>
                <!-- |<a href="./files/paper_Chinese_GVSL.pdf">&nbsp;中译版&nbsp;</a> -->
                </p>
            </td>
        </tr>
        <tr>
            <td>
                <p class="pub_title">Keyword-driven Image Captioning via Context-dependent Bilateral LSTM.</p>
                <p class="pub_author"><u><b>Xiaodan Zhang</b></u>, Shengfeng He, Xinhang Song, Pengxu Wei, Shuqiang Jiang, Qixiang Ye, Jianbin Jiao, Rynson W.H. Lau.<br/>
                <i>Proceedings of IEEE International Conference on Multimedia and Expo</i><br/>
                <font color="#922B21"><b>ICME. 2017</b></font>
                |<a href= "https://doi.org/10.1109/ICME.2017.8019525">&nbsp;Paper&nbsp;</a>
                |<a href="./files/bib_KIC.txt">&nbsp;Bibtex&nbsp;</a>
                <!-- |<a href="./files/paper_Chinese_GVSL.pdf">&nbsp;中译版&nbsp;</a> -->
                </p>
            </td>
        </tr>
        <tr>
            <td>
                <p class="pub_title">Rich Image Description Based on Regions.</p>
                <p class="pub_author"><u><b>Xiaodan Zhang</b></u>, Xinhang Song, Shuqiang Jiang, Qixiang Ye, Jianbin Jiao.<br/>
                <i>Proceedings of the 23rd ACM International Conference on Multimedia</i><br/>
                <font color="#922B21"><b>ACM MM. 2015</b></font>
                |<a href= "https://doi.org/10.1145/2733373.2806338">&nbsp;Paper&nbsp;</a>
                |<a href="./files/bib_RIDBR.txt">&nbsp;Bibtex&nbsp;</a>
                <!-- |<a href="./files/paper_Chinese_GVSL.pdf">&nbsp;中译版&nbsp;</a> -->
                </p>
            </td>
        </tr>
    </table>

    <h3>☆ Other Research</h3>
    <table class="imgtable" width="100%" bgcolor="#F0F0F0"></table>
        <tr>
            <td>
                <p class="pub_title">Multi-scale Superpixel Based Hierarchical Attention Model for Brain CT Classification.</p>
                <p class="pub_author">Xiao Song, <u><b>Xiaodan Zhang</b></u>, Junzhong Ji, Ying Liu<br/>
                <i>Journal of Visual Communication and Image Representation</i><br/>
                <font color="#922B21"><b>JVCIR 2023</b></font>
                |<a href= "https://doi.org/10.1016/j.jvcir.2023.103773">&nbsp;Paper&nbsp;</a>
                |<a href="./files/bib_MSBHA.txt">&nbsp;Bibtex&nbsp;</a>
                <!-- |<a href="./files/paper_Chinese_GVSL.pdf">&nbsp;中译版&nbsp;</a> -->
                </p>
            </td>
        </tr>
        <tr>
            <td>
                <p class="pub_title">Generic Attention-model Explainability by Weighted Relevance Accumulation.</p>
                <p class="pub_author">Yiming Huang, Aozhe Jia, <u><b>Xiaodan Zhang*</b></u>, and Jiawei Zhang<br/>
                <i>In Proceedings of the 5th ACM International Conference on Multimedia in Asia</i><br/>
                <font color="#922B21"><b>MM Asia 2023</b></font>
                |<a href= "https://doi.org/10.1016/j.jvcir.2023.103773">&nbsp;Paper&nbsp;</a>
                |<a href="./files/bib_MSBHA.txt">&nbsp;Bibtex&nbsp;</a>
                <!-- |<a href="./files/paper_Chinese_GVSL.pdf">&nbsp;中译版&nbsp;</a> -->
                </p>
            </td>
        </tr>
    </table>



<a id="awards" class="anchor"></a>
<h2>Awards and Honors</h2>
    <div>
        <ul>
            <li>High-level overseas returnees from Beijing 2022.</li>
            <li>International Postdoctoral Exchange Fellowship Program(Talent-Introduction Program) 2018</li>
        </ul>
    </div>



<a id="laboratory" class="anchor"></a>
<h2>Laboratory</h2>
<br><br>
<span style="color: blue; font-size: larger;">My laboratory currently has several NVIDIA deep learning servers. 
We welcome students from relevant fields such as computer science and mathematics who are eager to engage in research. 
Preference will be given to those with a solid foundation in deep learning and strong programming skills. 
Please indicate your CET-6, IELTS, or TOEFL scores in your application. 
The lab is in a phase of rapid development, and we hope everyone can strive for progress together!</span>

<!-- Services -->
<a id="services" class="anchor"></a>
<h2>Services</h2>

    
<p>Reviewer: </p>
<ul>
ACM MM 2024, CVPR 2024, ACL ARR 2024, MICCAI 2024, AAAI 2024.<br/>
ACM MM 2023, CVPR 2023, MICCAI 2023.
</ul>


</body>
</html>
